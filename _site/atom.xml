<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>annotatAR</title>
 <link href="http://arebe.github.io/annotatar//annotatar/atom.xml" rel="self"/>
 <link href="http://arebe.github.io/annotatar//annotatar/"/>
 <updated>2015-09-23T23:00:36-04:00</updated>
 <id>http://arebe.github.io/annotatar/</id>
 <author>
   <name>RB</name>
   <email>rfboyce+annotatar@gmail.com</email>
 </author>

 
 <entry>
   <title>Week 4 Scope and Usability</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/23/week4/"/>
   <updated>2015-09-23T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/23/week4</id>
   <content type="html">&lt;p&gt;Revisiting the project goals, scope, and affordances.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;reorienting&quot;&gt;Reorienting&lt;/h4&gt;

&lt;p&gt;Last Fall, I has the opportunity to work with the talented &lt;a href=&quot;http://docshop.space&quot;&gt;DocShop&lt;/a&gt; team on an experimental event called &lt;a href=&quot;http://docshop0.tumblr.com/&quot;&gt;Notes from El Saniyaa&lt;/a&gt; in which we worked with artist Lara Baladi to prototype her ongoing &lt;a href=&quot;http://www.tahrirarchives.com/&quot;&gt;Vox Populi&lt;/a&gt; project. This ambitious work is an interactive multimedia archive of the Arab Spring, specifically the Egyptian Revolution of 2011. The experience of working with archival material in a socially-aware setting has been a deep inspiration for annotatAR and its design goals.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/notes_poster.jpg&quot; alt=&quot;Notes from El Saniyya poster&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It was with great excitement that I received an email from Lara last week, with news of the next iteration of the project: a picnic in Dewey Square to commemorate the anniversary of &lt;a href=&quot;http://www.occupyboston.org/&quot;&gt;Occupy Boston&lt;/a&gt;, a collective protest and re-settlement of public space that occurred from September 30 - December 10, 2011 in solidarity with &lt;a href=&quot;http://occupywallst.org/&quot;&gt;Occupy Wall Street&lt;/a&gt; and other &lt;a href=&quot;https://en.wikipedia.org/wiki/Occupy_movement&quot;&gt;Occupy movements&lt;/a&gt; around the world.&lt;/p&gt;

&lt;p&gt;Lara is excited to utilized annotatAR as part of the commemorative picnic, and we are in the process of hashing out the details for incorporating my software. However, the overall goals and aesthetic of her event require some re-thinking of how to best to incorporate annotatAR as a digital tool. We’ve agreed that at this point it would be best to use annotatAR as a documentation tool rather than deploying it as a full-fledged augmented reality experience. &lt;/p&gt;

&lt;h4 id=&quot;goals-for-the-picnic&quot;&gt;Goals for the picnic&lt;/h4&gt;

&lt;p&gt;September 30 is approaching rapidly, and I’d really like to be able to utilize annotatAR to the fullest extent. My experience at the Internet Yami-Ichi was that, while the mechanics worked, there are many aesthetic improvements to be made.&lt;/p&gt;

&lt;p&gt;New focal points include:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Legibility of the tweet text through typography and color palette&lt;/li&gt;
  &lt;li&gt;Resolution of video&lt;/li&gt;
  &lt;li&gt;Screen capture &lt;/li&gt;
  &lt;li&gt;Switching between several hashtags &lt;/li&gt;
  &lt;li&gt;Displaying tweets from 2011 to capture the historicity of the current event&lt;/li&gt;
  &lt;li&gt;Filtering out URLs that clutter the image with illegible content&lt;/li&gt;
  &lt;li&gt;Locating the tweets in a 3D space to further spread them out and increase legibility&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;post-picnic-content&quot;&gt;Post-picnic content&lt;/h4&gt;

&lt;p&gt;Once we have screenshots created with annotatAR the next step is to generate an expressive media object using these images. Perhaps this takes the form of a multi-media collage. &lt;/p&gt;

&lt;p&gt;I’d like to incorporate text visualization from the tweets for a multi-modal presentation, as an interactive website along with static images and video. The end-user has become the archival artist (such as myself and Lara) and ultimately the general public. In this case success can be assessed by determining reactions of the audience, if the work elicits a sense of historicity and participation, and an emotive reaction. I believe this work also helps me process my experience of participating in Occupy, and commemorating it in an official capacity is an opportunity to orient my own experiences within a global context. My goal for this project is to do the same for other participants in Occupy - as well as provide a touchstone for folks who are interested in contemporary protest movements.&lt;/p&gt;

&lt;h4 id=&quot;usability-and-scope&quot;&gt;Usability and scope&lt;/h4&gt;

&lt;p&gt;This new orientation for annotatAR focuses more on the output of screenshots than usability in the sense of affordances to a naive end-user. Geolocation is unnecessary for this iteration and cross-browser and -platform compatibility become irrelevant.&lt;/p&gt;

&lt;p&gt;Narrowing the scope of the project to a known and tested platform (Firefox on a Galaxy 4G smart phone) makes the project more manageable and provides a clear direction for design decisions. Geolocative and “on-boarding” affordances of the UI are features that can wait until the visual design has been refined.&lt;/p&gt;

&lt;h4 id=&quot;further-planning&quot;&gt;Further planning&lt;/h4&gt;

&lt;p&gt;As I continue to work with Lara and the DocShop team to prepare for the event, I believe more design ideas will surface. I expect that the next week will be full of challenges, brainstorming, and new ideas.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Week 3 Beta Testing at NYC Internet Yami-Ichi</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/14/week3a/"/>
   <updated>2015-09-14T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/14/week3a</id>
   <content type="html">&lt;p&gt;In which we visit the internet black market and take some screenshots.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/brian_esser_yaminyc.jpg&quot; alt=&quot;NYC Internet Yami-Ichi (photo credit to Brian Esser)&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;preparation&quot;&gt;Preparation&lt;/h4&gt;

&lt;p&gt;I was tipped off to the existence of the &lt;a href=&quot;http://yami-ichi.biz/nyc/&quot;&gt;NYC Internet Yami-Ichi&lt;/a&gt; by some colleagues from &lt;a href=&quot;http://itp.nyu.edu/camp2015/&quot;&gt;ITP Camp at NYU&lt;/a&gt;. The event began in Japan and is devoted to the extrapolation of everything “internet-ish” into the real world. Due to my interest in net art and utilizing online interactions as an artistic medium, I was immediately interested in participating. It also seemed like an excellent place for the first test of annotatAR in the wild.&lt;/p&gt;

&lt;p&gt;I set the bar for the beta-test fairly low - the key here would be to see how and if people utilized the core functionality of tweets displayed on a real-time &lt;code&gt;getUserMedia&lt;/code&gt; video feed. I deployed a test version of the app on Meteor’s test server. The Meteor platform proved itself useful in this regard: it was quite easy to deploy multiple versions from the same code base by simply changing the URL in the &lt;code&gt;meteor deploy&lt;/code&gt; command.&lt;/p&gt;

&lt;p&gt;annotatAR achieved the minimal viable test build plus a few extra features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;geolocation (coordinates and accuracy) was displayed below the video feed - for testing purposes only&lt;/li&gt;
  &lt;li&gt;tweet data was displayed in decresing font size - the age of the tweet was linearly mapped to the font scale - tweets appeared as 50px in size and decreased down to 5px over the course of 8 hours&lt;/li&gt;
  &lt;li&gt;the databse stores the hashtag for the search that generates each the tweet&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;survey&quot;&gt;Survey&lt;/h4&gt;

&lt;p&gt;I also designed a brief user feedback survey and posted it on Google Forms. I also made a paper version (which is what I ended up utiliting in situ).&lt;/p&gt;

&lt;p&gt;The survey captures whether or not the video and tweet functions work, information about th edevice &amp;amp; browser, and some open-ended questions.&lt;/p&gt;

&lt;h4 id=&quot;internet-yami-ichi-deployment&quot;&gt;Internet Yami-Ichi Deployment&lt;/h4&gt;

&lt;p&gt;The &lt;a href=&quot;http://annotatar_yaminyc.meteor.com&quot;&gt;#yaminyc app&lt;/a&gt; was deployed the night before the event, and targeted at the Twitter hashtag “#yaminyc” where a couple of folks had already begun to interact. &lt;/p&gt;

&lt;p&gt;I acheived two separate user tests during the event. One was successful and generated some great feedback regarding next directions for the UI: a “selfie” mode, screencapture interface button, and an animated GIF generator. The second test was not as successful - it was an iPhone and it seemed that the phone did not ask the user for permission to connect to the &lt;code&gt;getUserMedia&lt;/code&gt; device at all. This may be a significant issue going forward, if iPhone defaults interfere with this browser funcitonality.&lt;/p&gt;

&lt;p&gt;I also took a number of screenshots at the event. It is quite an expressive way of documenting this type of gathering - one gets a sense of a crowd of virtual eavesdropping entities. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_00.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_01.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_02.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_03.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_04.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_05.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_06.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_07.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_08.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_09.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_10.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/20150912_yaminyc/annotatar_yaminyc_20150912_11.png&quot; alt=&quot;annotatAR at NYC Internet Yami-Ichi&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;lessons&quot;&gt;Lessons&lt;/h4&gt;

&lt;p&gt;I think that annotatAR was quite effective in achieving the union of virtual and real space in an expressive way. &lt;/p&gt;

&lt;p&gt;I was a bit frustrated with the quality of the web camera picture, I wonder if anything can be done to improve it.&lt;/p&gt;

&lt;p&gt;I’m also brainstorming about the next level of the project: the desktop site. Perhaps it should be a focal point for sharing screenshots, or perhaps the screenshots could be utilized in a larger work of some kind. I now have a databse of tweets from an event to experiment with, as a corpus for text analysis.&lt;/p&gt;

&lt;p&gt;I’m a bit concerned about the &lt;a href=&quot;http://iswebrtcreadyyet.com/&quot;&gt;failure of iOS&lt;/a&gt; to connect to the WebRTC protocol, which I was not expecting since it is supported by the versions of Firefox and Chrome that are on the iPhone device thtat was tested. I will address this in my upcoming post on scoping for compatibility and audience. &lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Week 2 Feedback and Learning</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/13/week2/"/>
   <updated>2015-09-13T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/13/week2</id>
   <content type="html">&lt;p&gt;In which annotatAR undergoes critique by two fellow capstone students, RB converses with Jen Kramer, and preparation is underway for the first beta deployment.&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;check-in-with-jen&quot;&gt;Check-in with Jen&lt;/h4&gt;

&lt;p&gt;Call with Jen K was super helpful in thinking about next steps for the design and how to justify decisions with demographics and user personas. It was great to have a chat about high-level project goals, and it was super helpful start to think about deliverables in terms of the December presentations. &lt;/p&gt;

&lt;p&gt;We reviewed the rubric and I’m going to revisit it in light of our conversation; the main advice was to try to define the criteria as specifically as possible so we are on the same page about the final deliverables. I will spend s bit of time thinking through the aesthetic qualities that are most important. Similarly, I will work to define a specific use-case for device compatibility and narrow the scope to what makes the most sense for the target audience demographic.&lt;/p&gt;

&lt;h4 id=&quot;feedback-from-pat--peg&quot;&gt;Feedback from Pat &amp;amp; Peg&lt;/h4&gt;

&lt;p&gt;My group members provided copius and helpful feedback - I think it really helped that I asked a couple of specific but somewhat open-ended questions in my video :) The main areas where I hoped to receive suggestions were user experience and scaling the project down the road. Overall, I’m hearing that a simple interface for the mobile site is preferable - the tweets should be obvious and contrasting. Scaling could go in various directions - Pat had some suggestions about devices which I will consider when I revisit my grading rubric. I look forward to incorporating the thoughtful ideas that Peg and Pat have shared with me.&lt;/p&gt;

&lt;h4 id=&quot;learning-meteor&quot;&gt;Learning Meteor&lt;/h4&gt;

&lt;p&gt;I went to a Meteor meet-up in New York and met some awesome Meteor folks. I learned about &lt;a href=&quot;https://www.discovermeteor.com/&quot;&gt;Discover Meteor&lt;/a&gt;, the guide to getting started. I also learned about how Meteor handles authorization and authentication, why you might want to render views on the server (which is functionality that will part of the next release of Meteor), and also heard about the Meteor package &lt;a href=&quot;https://atmospherejs.com/houston/admin&quot;&gt;houston&lt;/a&gt; for implementing a database UI. &lt;/p&gt;

&lt;p&gt;In preparing for the beta deployment at the &lt;a href=&quot;http://yami-ichi.biz/nyc/&quot;&gt;Internet Yami-Ichi NYC&lt;/a&gt;, I realized that an HTML5 game engine might be a suitable platform for displaying the tweet database. Such a mobile framework wold handle the canvas on the mobile app - something as simple as resizing the video to fit the screen seems needlessly complex to code from scratch. So I’m seeking a mobile-first render engine. Some candidates:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.pixijs.com/&quot;&gt;Pixi.js&lt;/a&gt; - a 2D webgl renderer&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://phaser.io&quot;&gt;Phaser&lt;/a&gt; - HTML 5 game framework that’s (previously) based on Pixi&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://famous.org/&quot;&gt;Famous&lt;/a&gt; - js library for animations &amp;amp; interfaces (not as much doc)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;looking-ahead-this-week&quot;&gt;Looking ahead this week&lt;/h4&gt;

&lt;p&gt;The upcoming week, I will develop a user persona based on the demographics of twitter users, sketch out the app database design, and mock up the UI for the mobile site.&lt;/p&gt;

&lt;p&gt;I’ll also be posting a recap of this weekend’s beta test as its own post.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Week 1 Summer Progress</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/04/week1/"/>
   <updated>2015-09-04T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/04/week1</id>
   <content type="html">&lt;p&gt;In which our hero recounts the details of this summer’s work….&lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;user-interaction-paradigm&quot;&gt;User interaction paradigm&lt;/h4&gt;

&lt;p&gt;annotatAR was inspired by a project I worked on in Fall 2014, &lt;a href=&quot;http://docshop0.tumblr.com/&quot;&gt;Notes from El Saniyya&lt;/a&gt;. As part of &lt;a href=&quot;http://docshop.space/&quot;&gt;DocShop at metaLab&lt;/a&gt;, I worked with Egyptian artist Lara Baladi to create a prototype of a living timeline of the Arab Spring. The &lt;em&gt;Notes…&lt;/em&gt; event was highly participatory and we wondered what the next steps for engaging with a multi-media archive might be like.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You walk into a gallery space, with a curved wall with a huge timeline, each point on the timeline is an event in the Arab Spring / Tahrir Square 21 days. you want to add your own comment to the timeline, reacting to something on the timeline that triggered a memory or emotion - given any possible technology or material, how would you leave a message?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is motivation for utilizing an augmented reality platform, and Twitter as a common social interface.&lt;/p&gt;

&lt;h4 id=&quot;meteor&quot;&gt;Meteor&lt;/h4&gt;

&lt;p&gt;The major accomplishment achieved this summer was getting started with &lt;a href=&quot;http://docs.meteor.com/#/full/&quot;&gt;Meteor.js&lt;/a&gt;. After reading docs and going through an example project tutorial, I was convinced that this was the technology on which I should build annotatAR. What first drew me to Meteor is the ability to code everything in Javascript, the active community, and the well-designed forward-looking codebase. I sat with a friend for an informational session to learn about how to utilize &lt;a href=&quot;https://www.eventedmind.com/feed/meteor-what-is-meteor-bindenvironment&quot;&gt;asynchronous external requests&lt;/a&gt; in Meteor, through &lt;a href=&quot;https://meteorhacks.com/fibers-eventloop-and-meteor&quot;&gt;fibers&lt;/a&gt; and &lt;code&gt;Meteor.bindEnvironment&lt;/code&gt;. I’m starting to see even more value in how Meteor encourages code modularization, which may be quite helpful as the project develops.&lt;/p&gt;

&lt;h4 id=&quot;alpha-site&quot;&gt;Alpha site&lt;/h4&gt;

&lt;p&gt;With my newly acquired knowledge of Meteor, I built a test application called &lt;em&gt;truthtweets&lt;/em&gt;, which connects to the &lt;a href=&quot;https://dev.twitter.com/streaming/public&quot;&gt;Twitter Firehose API&lt;/a&gt; and overlays tweet texts that utilize the hashtag &lt;em&gt;#truth&lt;/em&gt; onto a video stream from &lt;code&gt;getUserMedia&lt;/code&gt; element. Voilà!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/annotatar/assets/images/screencap_20150904.png&quot; alt=&quot;truthtweets app&quot; /&gt;&lt;/p&gt;

&lt;h4 id=&quot;next-directions&quot;&gt;Next directions&lt;/h4&gt;

&lt;p&gt;In the short term, the mobile application has a number of refinements to be achieved:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;strike&gt;twitter api config file - untracked (not shared on github)&lt;/strike&gt;
    &lt;p&gt;done! - now using settings.json&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;resize navigator to fit device screen&lt;/li&gt;
  &lt;li&gt;use accelerometer data to detect motion and update tweet position&lt;/li&gt;
  &lt;li&gt;turn the stream on and display new tweets&lt;/li&gt;
  &lt;li&gt;change alpha based on tweet createdAt&lt;/li&gt;
  &lt;li&gt;deploy to meteor cloud or other web server&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;what if tweets became colored to reflect the background video feed? - lexigraph&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;looking-ahead-this-month&quot;&gt;Looking ahead this month&lt;/h4&gt;

&lt;p&gt;My first &lt;a href=&quot;/annotatar/2015/09/02/milestones&quot;&gt;project milestone&lt;/a&gt; will be next week, when I deploy a beta version of the application on a live server and test it at the &lt;a href=&quot;http://yami-ichi.biz/nyc/&quot;&gt;New York City Internet Yami-Ichi&lt;/a&gt; event by giving the URL out to a (small) number of attendees. This early-stage test will be crucial in refining the user interactions and aesthetics. In addition to the application itself, I will design a brief Google forms survey to collect UX feedback.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Capstone Project Grading Rubric</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/03/grading/"/>
   <updated>2015-09-03T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/03/grading</id>
   <content type="html">&lt;p&gt;As part of this week’s assignments, I have developed a grading rubric for annotatAR, for the scope of this fall’s Capstone Design Studio. This rubric has six dimensions, with three criteria each. The dimensions are categorized in two sub-sections: &lt;em&gt;Mobile Site&lt;/em&gt; and &lt;em&gt;Desktop Site&lt;/em&gt;. The points are weighted to emphasize the &lt;em&gt;Mobile Site&lt;/em&gt;, with a total possible score of 27 points.&lt;/p&gt;

&lt;hr /&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;em&gt;Mobile Site (18pts total)&lt;/em&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Excellent (6pts)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Competent (4pts)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Needs Work (1pt)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Functionality&lt;/strong&gt; :: Users can overlay tweets on a video stream; Device compatibility;  Geolocative;  Users can take screenshot&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 3/4 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt;= 3 requirements&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Aesthetics&lt;/strong&gt; :: Tweet metadata is visually encoded; Tweet position changes with device motion; Appealing visual design&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 2/3 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt;= 2 requirements&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt; :: Deployable at a variety of events; Github repo + documentation for further development&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 1/2 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt; 1 requirement&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;&lt;em&gt;Desktop Site (9pts total)&lt;/em&gt;&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Excellent (3pts)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Competent (2pts)&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Needs Work (1pt)&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Functionality&lt;/strong&gt; :: Users can view event-specific video with tweet overlay; Cross-browser compatibility&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 1/2 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt; 1 requirement&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Aesthetics&lt;/strong&gt; :: Tweet metadata is visually encoded; Timeline of event is expressed visually&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 1/2 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt; 1 requirement&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Scalability&lt;/strong&gt; :: Deployable for multiple events; Integrates with other social media feeds&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets all requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets 1/2 requirements&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Meets &amp;lt; 1 requirement&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
</content>
 </entry>
 
 <entry>
   <title>Capstone Project Milestones</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/09/02/milestones/"/>
   <updated>2015-09-02T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/09/02/milestones</id>
   <content type="html">&lt;p&gt;As part of this week’s set of assignments, I have revisited the project milestones for annotatAR this fall. &lt;/p&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;beta-test-at-the-nyc-internet-yami-ichihttpyami-ichibiznyc&quot;&gt;Beta-test at the &lt;a href=&quot;http://yami-ichi.biz/nyc/&quot;&gt;NYC Internet Yami-Ichi&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;12 Sept 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mobile site deployed on a live server&lt;/li&gt;
  &lt;li&gt;Displays tweet stream overlaid on &lt;code&gt;getUserMedia&lt;/code&gt; element&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;device-sensing&quot;&gt;Device sensing&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;30 Sept 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Geolocation-aware&lt;/li&gt;
  &lt;li&gt;Access device accelerometer data&lt;/li&gt;
  &lt;li&gt;Map tweet position to 3D model&lt;/li&gt;
  &lt;li&gt;Determine whether or not to compile to native app(s)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;aesthetic-refinements-on-mobile&quot;&gt;Aesthetic refinements on mobile&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;16 Oct 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Style tweets based on timestamp&lt;/li&gt;
  &lt;li&gt;Screenshot functionality&lt;/li&gt;
  &lt;li&gt;User testing of mobile&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;desktop-site-minimum-viable-product&quot;&gt;Desktop site minimum viable product&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;30 Oct 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Display video from event with tweets overlaid&lt;/li&gt;
  &lt;li&gt;User testing of desktop&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;desktop-site-refinements&quot;&gt;Desktop site refinements&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;20 Nov 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Text analysis (some or all of the following):
    &lt;ul&gt;
      &lt;li&gt;Sentiment analysis&lt;/li&gt;
      &lt;li&gt;Keyword parsing&lt;/li&gt;
      &lt;li&gt;Spatial and/or color encoding&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Scrub / navigate on time dimension&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;platform-scalability&quot;&gt;Platform scalability&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;04 Dec 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Github repo with description and instructions for deployment&lt;/li&gt;
  &lt;li&gt;Integrate with existing social media (share buttons)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h4 id=&quot;bonus-features&quot;&gt;Bonus features&lt;/h4&gt;
&lt;p&gt;&lt;em&gt;11 Dec 2015&lt;/em&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User interface for deploying new app for an event&lt;/li&gt;
  &lt;li&gt;Compile to native Android app (if necessary)&lt;/li&gt;
  &lt;li&gt;Multiple views of augmented reality:
    &lt;ul&gt;
      &lt;li&gt;Tweet text becomes lexograph of video stream&lt;/li&gt;
      &lt;li&gt;Select variety of encoding for sentiments or keywords&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Welcome to annotatAR's Blog</title>
   <link href="http://arebe.github.io/annotatar//annotatar/2015/08/31/welcome/"/>
   <updated>2015-08-31T00:00:00-04:00</updated>
   <id>http://arebe.github.io/annotatar//2015/08/31/welcome</id>
   <content type="html">&lt;p&gt;This blog will track my progress on my ALM capstone project, annotatAR. Details about the motivation, design, and prospective schedule are part of &lt;a href=&quot;/annotatar/assets/files/ALM_Capstone_Proposal_RBoyce_v3.2.pdf&quot;&gt;the project proposal&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;h3 id=&quot;some-links-to-track&quot;&gt;Some links to track:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#&quot;&gt;annotatAR live site - coming soon!&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://canvas.harvard.edu/courses/4308&quot;&gt;Capstone design studio site&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;summer-work&quot;&gt;Summer work&lt;/h3&gt;

&lt;p&gt;Over the summer, I learned a bit about &lt;a href=&quot;https://www.meteor.com/&quot;&gt;meteor.js&lt;/a&gt; and began building a version 0 of the site, which connects to the &lt;a href=&quot;https://dev.twitter.com/streaming/public&quot;&gt;Twitter API&lt;/a&gt;, grabs tweets with a particular hashtag, and displays them on top of a video feed from &lt;a href=&quot;https://developer.mozilla.org/en-US/docs/Web/API/Navigator/getUserMedia&quot;&gt;getUserMedia&lt;/a&gt;. &lt;/p&gt;

&lt;h3 id=&quot;next-steps&quot;&gt;Next steps&lt;/h3&gt;

&lt;p&gt;While the most basic form of this mechanic “works,” there is much to be done in terms of styling, user interactions, and geolocation. Additionally, meta-analysis of the tweets will add layers of semantics to both the mobile site and eventually to a desktop archival version.&lt;/p&gt;
</content>
 </entry>
 

</feed>
